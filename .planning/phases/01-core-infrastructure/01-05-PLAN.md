---
phase: 01-core-infrastructure
plan: 05
type: execute
wave: 1
depends_on: []
files_modified:
  - src/butler/cli/main.py
  - src/core/router.py
  - tests/core/test_router.py
autonomous: false
requirements: [VOICE-02, VOICE-03, VOICE-04, OUTPUT-01]
gap_closure: true

must_haves:
  truths:
    - "CLI entry point works: butler process-voice triggers voice processing"
    - "Voice files are transcribed and appear in Obsidian daily notes"
    - "Event chain connects: input_received → note_routed → note_written"
  artifacts:
    - path: "src/butler/cli/main.py"
      provides: "CLI process-voice command implementation"
      contains: "def process_voice"
    - path: "src/core/router.py"
      provides: "Simple event router for MVP"
      contains: "def simple_route"
  key_links:
    - from: "src/butler/cli/main.py"
      to: "src/core/router.py"
      via: "import and setup"
      pattern: "from src.core.router"
    - from: "src/core/router.py"
      to: "src/core/event_bus.py"
      via: "signal subscription"
      pattern: "input_received.connect"
---

<objective>
Connect CLI process-voice command to the voice processing pipeline, enabling launchd-triggered voice transcription to flow through to Obsidian daily notes.

Purpose: The launchd plist calls `butler process-voice` when voice memos are detected. This command must initialize plugins, bridge events, and process pending audio files.

Output: Working CLI command that completes the voice-to-Obsidian pipeline.
</objective>

<execution_context>
@/Users/caffae/.config/opencode/get-shit-done/workflows/execute-plan.md
@/Users/caffae/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-core-infrastructure/01-03-SUMMARY.md

# Existing implementations

@src/plugins/voice_input/plugin.py - has process_file() and scan_folder()
@src/plugins/daily_writer/plugin.py - listens to note_routed, writes to daily files
@src/core/plugin_manager.py - loads plugins from directory
@src/core/event_bus.py - signal definitions (input_received, note_routed, note_written)
@src/butler/cli/main.py - current stub at process_voice command
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Simple Router Module</name>
  <files>src/core/router.py, tests/core/test_router.py</files>
  <action>
    Create a simple event router that bridges `input_received` to `note_routed` for MVP.

    The router module (src/core/router.py) should:
    1. Define a `SimpleRouter` class or `simple_route()` function
    2. Subscribe to `input_received` signal from event_bus
    3. On receiving input, emit `note_routed` with destination="daily"
    4. Include source, text, and timestamp in the routed event

    This is NOT the AI-powered router (Phase 5) - it's a simple passthrough that routes all voice input to daily notes.

    Event flow:
    - voice_input emits: input_received(sender="voice_input", text=..., source="voice", confidence=..., duration=...)
    - router transforms to: note_routed(sender="router", text=..., source="voice", destination="daily", timestamp=...)

    Add tests for:
    - Router subscribes to input_received
    - Router emits note_routed with correct fields
    - Router includes destination="daily" by default

  </action>
  <verify>
    bun test tests/core/test_router.py
  </verify>
  <done>
    Router module exists, tests pass, event bridge validated
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement CLI process-voice Command</name>
  <files>src/butler/cli/main.py</files>
  <action>
    Replace the stub `process_voice` command with a working implementation.

    The command should:
    1. Initialize logging configuration (use existing setup from config)
    2. Create PluginManager with src/plugins directory
    3. Load voice_input and daily_writer plugins
    4. Initialize the SimpleRouter to bridge events
    5. Get voice_input plugin instance
    6. Call voice_input.scan_folder() to find audio files
    7. For each file, call voice_input.process_file()
    8. Report results (files processed, errors)
    9. Exit with appropriate code (0 for success, 1 for errors)

    Implementation pattern:
    ```python
    @cli.command()
    def process_voice():
        """Trigger voice processing (called by launchd)."""
        from pathlib import Path
        from src.core.plugin_manager import PluginManager
        from src.core.router import SimpleRouter

        # Initialize router to bridge events
        router = SimpleRouter()
        router.start()

        # Load plugins
        plugin_dir = Path(__file__).parent.parent.parent / "plugins"
        manager = PluginManager(plugin_dir)
        manager.load_plugins()

        # Get voice_input plugin
        voice_input = manager.get_plugin("voice_input")
        if not voice_input:
            click.echo("Error: voice_input plugin not found", err=True)
            raise SystemExit(1)

        # Scan and process
        files = voice_input.scan_folder()
        processed = 0
        errors = 0

        for file_path in files:
            if voice_input.process_file(file_path):
                processed += 1
            else:
                errors += 1

        click.echo(f"Processed {processed} file(s), {errors} error(s)")
    ```

    DO NOT:
    - Add complex error handling beyond basic try/except
    - Add background processing (that's what launchd is for)
    - Block indefinitely - process what's there and exit

  </action>
  <verify>
    bun test tests/cli/test_main.py -t process_voice
    python -c "from butler.cli.main import process_voice; print('import ok')"
  </verify>
  <done>
    CLI command processes voice files, emits events, writes to Obsidian
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify End-to-End Voice Pipeline</name>
  <files></files>
  <action>
    Human verification of complete voice processing pipeline.
    
    Verify that:
    - CLI command initializes and runs without errors
    - Voice files are processed and transcribed
    - Daily notes are created/updated in Obsidian
    - Event chain flows correctly through the system
  </action>
  <what-built>
    Complete voice processing pipeline: CLI command → router → voice_input plugin → daily_writer plugin → Obsidian daily note
  </what-built>
  <how-to-verify>
    1. Place a test audio file in ~/Music/Voice Memos (or create a dummy .m4a)
    2. Run: `butler process-voice`
    3. Check that:
       - Command outputs "Processed X file(s)"
       - Daily note created/updated in ~/Documents/Obsidian/Vault/Daily/YYYY-MM-DD.md
       - Note contains transcribed text with timestamp

    Alternative quick test:
    ```bash
    # Create test audio file
    mkdir -p ~/Music/Voice\ Memos
    touch ~/Music/Voice\ Memos/test.m4a

    # Run command (will fail gracefully on non-audio, but shows pipeline works)
    butler process-voice
    ```

  </how-to-verify>
  <verify>Human runs butler process-voice and confirms output</verify>
  <done>User types "approved" to confirm pipeline works</done>
  <resume-signal>Type "approved" or describe issues found</resume-signal>
</task>

</tasks>

<verification>
- [ ] Router module bridges input_received → note_routed
- [ ] CLI process-voice command initializes plugins
- [ ] CLI scans for audio files in watched folder
- [ ] CLI processes each file through voice_input plugin
- [ ] Events flow: input_received → note_routed → note_written
- [ ] Test coverage for router module
- [ ] Manual verification: voice memo appears in Obsidian daily note
</verification>

<success_criteria>
CLI command `butler process-voice` successfully processes voice memos through the complete pipeline to Obsidian daily notes. The launchd plist can trigger this command and voice memos will be transcribed and written to the correct daily file.
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-infrastructure/01-05-SUMMARY.md`
</output>
